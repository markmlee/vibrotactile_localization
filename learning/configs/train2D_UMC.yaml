# ----- wandb log parameters -----
log_wandb: True
wandb_run_name: "v2_v3data_Multi_ResNet50_MLP_selfattn_audio_state_v2_nopos"
wandb_project: "audio_localization8"

#proprio: v2_v3_data_Multi_ResNet50_MLP_xt_xdot_only_nopos
#audio: resnet_b256_lr1e3
#audio + proprio: v2_v3_data_Multi_ResNet50_MLP_xt_xdot
#audio + phase: v2_v3data_Multi_ResNet50_MLP_selfattn_audio_gcc
#audio + proprio + phase: v2_v3data_Multi_ResNet50_MLP_selfattn_audio_state_gcc

data_dir: /home/mark/audio_learning_project/data/wood_v2_v3_combined/ #wood_v2_v3_combined/ #wood_horizontal_opposite_verticalv3_2/ #wood_suctionOnly_horizontal_opposite_verticalv2/ #wood_T25_L42_Horizontal_opposite_v3_mini/ #/ #wood_T12_T22_T32_L42_T22_L80_Horizontal_combined_suction_opposite/ #wood_suctionOnly_horizontal_opposite_verticalv2/
background_dir: /home/mark/audio_learning_project/data/franka_constant/no_contact/trial0/
transform: mel

device_list: [2]
num_channel: 6
max_num_frames: 88200 #2 sec duration during data collection

window_frame: 66150 #[44100 for 1 sec for input_spectrogram_bins = 138], [66150 for 1.5 sec for input_spectrogram_bins = 345] 
CNN_layer_size: 4864 #[torch.nn.Linear(1536,512) for 0.2 second input],[#torch.nn.Linear(4864,512) for 1.0 second input]
sample_rate: 44100
n_fft: 512
hop_length: 128
input_spectrogram_bins: 345 #[138 for 0.2s duration for NFFT512, HOP 64], [345 for 1s duration for NFFT512, HOP 128]
n_mels: 50
resample_rate: 11025
load_meanvar_output: False

# ----- preprocessing parameters -----
subtract_background: True # ***** key parameter *****
normalize_audio_data: True # ***** key parameter *****


# ----- augmentation param -----
augment_data: True #for general _getitem_ modification enable/disable
augment_timeshift: True # ***** key parameter ***** (upon init dataset)
affine_transform: True
augment_timemask: True #upon getitem in dataloader
augment_freqmask: True #upon getitem in dataloader


# ----- training parameters -----

model_path: /home/mark/audio_learning_project/models
checkpoint_dir: ??? #to be filled in by hydra

batch_size: 128
val_batch_size: 128
learning_rate: 0.005


# ----- output representation parameters -----
output_representation: 'xy' #'height_radianclass' #'height' #'xy' #'radian' 
output_representation_normalize: False #for ablation study, to normalize the output representation


# ----- training hypertuning parameters -----
train_epochs: 100 #100 for proprioception, 200 for audio only
log_frequency: 1
eval_frequency: 1


# ----- visualization parameters -----
inspect_data_label: False # to iteratively visualize the audio & GT label in 3D plot 
visualize_subtract_background: False
visuaize_dataset: False # to visualize the dataloader
visuaize_regression: True # for evaluation, to visualize the regression output 

# -------- debugging --------

save_meanvar_output: True

cylinder_radius: 0.06 #in meters